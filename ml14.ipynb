{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "Supervised learning has  the presence of a supervisor as a teacher. Basically supervised learning is when we teach or train the machine using data that is well labelled. Which means some data is already tagged with the correct answer. After that, the machine is provided with a new set of examples(data) so that the supervised learning algorithm analyses the training data(set of training examples) and produces a correct outcome from labelled data.Since the learning has happended by obeserving common patterns in data,when new data is produced,it will make predictions.This learning can be used in classification & regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "1. cancer prediction-Based on symptons classify data to having cancer and without cancer\n",
    "2.Classification — machine learning algorithms can help to determine and label the kind of disease or medical case you’re dealing with.\n",
    "3. Regreesionn model can be used to predict the blood sugar& cholestrol levels based on various input factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "Regression-predicting the price of a house based on city,amneties available,crime rates etc\n",
    "Classification-Predict whether it is going to rain today or not.\n",
    "Text recognition\n",
    "Spam detection\n",
    "Customer sentiment analysis\n",
    "Object detection (e.g. face detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "Classification is used to classify data into classes based on input parameters.Class be 1 & 0.In Classification, we try to find the decision boundary, which can divide the dataset into different classes.\n",
    "Regression is used to get discrete numbers.The task of the Regression algorithm is to find the mapping function to map the input variable(x) to the continuous output variable(y).In Regression, we try to find the best fit line, which can predict the output more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "1 Email Spam Detector-classify spam emails\n",
    "2. Naive Bayes - In text analysis, it can be used to categorize words or phrases as belonging to a preset “tag” (classification) or not\n",
    "3. SVM- Classification of images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6\n",
    "Supervised learning model used for calssification & regression.The objective is to find a hyperplane which can classify N dimensional data that distinctively classify the data.N depends on no of features.Out of all planes those panes where distance between data points on each side and plane is maximum is considered.In non dimensional data SVM solves this by creating a new variable using a kernel. That plane is called hard margin.Effective in high dimensional cases\n",
    "Its memory efficient as it uses a subset of training points in the decision function called support vectors\n",
    "Different kernel functions can be specified for the decision functions and its possible to specify custom kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\n",
    "Misclassification costs allow you to specify the relative importance of different kinds of prediction errors. Misclassification costs are basically weights applied to specific outcomes. The cost parameter decides how much an SVM should be allowed to “bend” with the data. For a low cost, you aim for a smooth decision surface and for a higher cost, you aim to classify more points correctly. It is also simply referred to as the cost of misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\n",
    "\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier.If we remove support vectors hyperplane would change.These points create SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\n",
    "\n",
    "Kernel Function is a method used to take data as input and transform it into the required form of processing data. “Kernel” is used due to a set of mathematical functions used in Support Vector Machine providing the window to manipulate the data.Kernel Function generally transforms the training set of data so that a non-linear decision surface is able to transform to a linear equation in a higher number of dimension spaces.\n",
    "eg : Uniform kernels,Gaussian kernels,Epanechnikov kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\n",
    "\n",
    "Kernal function,parameters of the kernel and the soft margin parameter C.For large values of C, the penalty for misclassifying points is very high, so the decision boundary will perfectly separate the data if possible.The SVM’s are less effective when  The data is noisy and contains overlapping points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11\n",
    "\n",
    "SVM works relatively well when there is a clear margin of separation between classes.\n",
    "SVM is more effective in high dimensional spaces.\n",
    "SVM is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "SVM is relatively memory efficient\n",
    "SVM has L2 Regularization feature. So, it has good generalization capabilities which prevent it from over-fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12\n",
    "\n",
    "SVM algorithm is not suitable for large data sets. SVM does not perform very well when the data set has more noise i.e. target classes are overlapping.\n",
    "Choosing correct Kernal function is difficult\n",
    "Feature scaling required and computationally heavy\n",
    "Difficult to interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13\n",
    "#1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #3\n",
    " \n",
    " \n",
    " Before learning a model given a data and a learning algorithm, there are a few assumptions a learner makes about the algorithm.This is Inductive bias\n",
    "In the case of decision trees, the depth of the tress is the inductive bias. If the depth of the tree is too low, then there is too much generalisation in the model. Similarly, if the depth of the tree is too much, there is too less generalisation and while testing the model on a new example.Also it chooses nodes with high information gain over low IG nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14\n",
    "1. No training period- KNN is called Lazy Learner (Instance based learning). It does not learn anything in the training period. It does not derive any discriminative function from the training data.\n",
    "2. New data can be added seamlessly which will not impact the accuracy of the algorithm.\n",
    "3. KNN is very easy to implement. There are only two parameters required to implement KNN i.e. the value of K and the distance function.Easy to tune\n",
    "4. Variety of distance criteria to be choose from-Euclidean Distance,Hamming Distance ,Manhattan Distance\n",
    "5 Can be used both for Classification and Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15\n",
    "1. K-NN slow algorithm: K-NN might be very easy to implement but as dataset grows efficiency or speed of algorithm declines very fast.\n",
    "2. KNN woks with small number of input variables but as dimension increases KNN struggles   \n",
    "3. Features need to be scaled in KNN\n",
    "4.Optimal number of neighbors in KNN decides best classification.It is difficult to find k\n",
    "5.Imbalanced data causes problems: k-NN doesn’t perform well on imbalanced data.\n",
    "6.Sensitive to outliers and missing values need to be treated    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#16\n",
    "Decision trees are supervised learning techniques for classification and regression.The model evaluates by splitting data to several nodes and leaf nodes. The leaves are the decisions or the final outcomes. And the decision nodes are where the data is split.Nodes having low on Gini impurity or high information gain splits and every time this process is done for splitting.Final result will be average for regression adn probability for classification.Decision trees are easier to understand and interpret.Pruning can be done to make a generalized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "In decision trees,nodes are the features of dataset.Based on low gini impurity or high information gain,the nodes split into several branches.Leaf nodes are the nodes where further splitting is not possible.All the information is available in that node or IG=0.From leaf node the model make conclusions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 \n",
    "Entropy is the measure of randomness.In decision trees entropy is used to split a node into several nodes by calculating uncertainty in a group of observations.If a node has high entropy means it has low information gain and the node will not split.Each time a tree is constructed,the node with high information gain is selected as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#19\n",
    "The information gained in the decision tree can be defined as the amount of information improved in the nodes before splitting them for making further decisions.The balanced nodes or most impure nodes require more information to describe.Nodes having single class do not need any information gain.The ndes with high information gain are selected for splitting.By more information gain homogenous nodes can be obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20\n",
    "1. Easy to understand and interpret.So we can understand the flow of tree.\n",
    "2. No scaling or normalisation is required before training.\n",
    "3. Missing values are not affected in the model\n",
    "4. Pruning techniques allows the control of depth and no of leaf nodes thereby giving more generalised model.\n",
    "5. can handle non linear dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#21\n",
    "1.  A small change in the data can result in a major change in the structure of the decision tree, which can convey a different result from what users will get in a normal event. \n",
    "2. decision trees are less effective in making predictions when the main goal is to predict the outcome of a continuous variable\n",
    "3. As the model complexity increases,results in overfitted model.\n",
    "4. Not every nodes participate in decision making causing increase in bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#22\n",
    "Random forest is a supervised learning model for classification and regression.It uses an ensemble technique which implements bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree.This results in low biased model.The class with most value of votes(classification) or average(regression) is the predicted value.Scaling,normalisation and missing values are automatically handled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
